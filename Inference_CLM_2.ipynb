{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DS-yfleN6IK9"
      },
      "outputs": [],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch"
      ],
      "metadata": {
        "id": "zdhtJMbe9ieY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(\"RWKV/rwkv-raven-1b5\", torch_dtype=torch.float16).to(0)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"RWKV/rwkv-raven-1b5\")"
      ],
      "metadata": {
        "id": "czXanMio-f9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "q1xZcnKx5Txd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee345d0f-4219-44b6-ad57-4f19b54e48c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One upon a time, during ancient years... a king must fight against his opponent while an agent follows that opposing and a referee watches to prevent fights. Such things became common many days.... For example here to demonstrate for the world in sports they would come together:\n",
            "\n",
            " A big strong man is battling strong body\n",
            " He wrestles and punches others up right or at right into himself! (Rap sheet... with great joy!! He could kill with pleasure on himself.) They had killed the biggest monster to take his head all through history: to conquer everything is even... and have the opportunity!!  (As they started an actual contest where those around are not at danger... to save as best when fighting...) to become the champion:\n",
            "\n",
            " From there for real if all of life came as such great contests of life's reality's life or their opponents as before from being good friends  with his mother he couldn't do because they do: in so small amount with another huge monster of a foe... and\n"
          ]
        }
      ],
      "source": [
        "prompt = \"One upon a time\"\n",
        "\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\").to(0)\n",
        "output = model.generate(\n",
        "                        inputs[\"input_ids\"],\n",
        "                        max_length=200,\n",
        "                        min_length=200,\n",
        "                        # num_return_sequences=1,\n",
        "                        top_k=70,\n",
        "                        top_p=1.2,\n",
        "                        temperature=2.0,\n",
        "                        repetition_penalty=2.0,\n",
        "                        # num_beams=5,\n",
        "                        # length_penalty=0.8,\n",
        "                        # penalty_alpha=0.5,\n",
        "                        do_sample=True,\n",
        "                        use_cache=True\n",
        "                        )\n",
        "print(tokenizer.decode(output[0].tolist(), skip_special_tokens=True))\n",
        "torch.cuda.empty_cache()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}